  
â— Watchdog Adaptado - Listo para Probar âœ“  
  
Â He implementado dos fixes crÃ­ticos para el sistema de auto-recovery:  
  
Â Fix #1: Double-Close Panic âœ“  
  
Â El panic original estÃ¡ resuelto. El worker ahora puede reiniciarse limpiamente.  
  
Â Fix #2: Watchdog Adaptativo âœ“  
  
Â Problema: El watchdog tenÃ­a un timeout fijo de 30 segundos, pero con 0.1 Hz (1 inferencia cada 10s), el  
Â worker puede estar saludable sin emitir nada por mÃ¡s de 30s.  
  
Â SoluciÃ³n Implementada (orion.go:395-405):  
Â // Timeout adaptativo: max(30s, 3 Ã— periodo_de_inferencia)  
Â inferencePeriod := 1.0 / inferenceRate Â // 0.1 Hz â†’ 10s  
Â adaptiveTimeout := 3 * inferencePeriod Â Â // 3 Ã— 10s = 30s  
  
Â Tabla de Timeouts:  
Â | Inference Rate | Period | Watchdog Timeout |  
Â |----------------|--------|------------------|  
Â | 1.0 Hz Â Â Â Â Â Â Â Â | 1s Â Â Â Â | 30s (min) Â Â Â Â Â Â Â |  
Â | 0.5 Hz Â Â Â Â Â Â Â Â | 2s Â Â Â Â | 30s (min) Â Â Â Â Â Â Â |  
Â | 0.1 Hz Â Â Â Â Â Â Â Â | 10s Â Â Â | 30s Â Â Â Â Â Â Â Â Â Â Â Â Â |  
Â | 0.05 Hz Â Â Â Â Â Â Â | 20s Â Â Â | 60s Â Â Â Â Â Â Â Â Â Â Â Â Â |  
Â | 0.01 Hz Â Â Â Â Â Â Â | 100s Â Â | 300s (5 min) Â Â Â Â |  
  
Â ---  
Â â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
Â Adaptive Systems: El watchdog ahora respeta la semÃ¡ntica del dominio - si configuraste el sistema para  
Â inferir cada 10 segundos, no tiene sentido declararlo "hung" a los 30s. El timeout de 3 ciclos completos es  
Â un patrÃ³n comÃºn en systems monitoring (similar a Kubernetes liveness probes).  
  
Â Configuration Coupling: Notar que el watchdog lee MaxInferenceRateHz directamente del config, creando un  
Â acoplamiento intencional. Esto garantiza que el health check siempre estÃ¡ sincronizado con el rate lÃ­mit  
Â configurado.  
Â â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
  
Â ---  
Â Para Probar Manualmente:  
  
Â 1. Arranca el servicio con make run  
Â 2. Cambia el rate a 0.05 Hz (1 inferencia cada 20 segundos):  
Â make config-rate Â # Selecciona 0.05 Hz  
Â 3. Espera 60 segundos sin que el watchdog se active prematuramente  
Â 4. Verifica en logs que el timeout adaptativo es 60s:  
Â "watchdog_timeout_s": 60  
  
Â Nota: AÃºn puede haber un issue con el stream delivery despuÃ©s del rate change (por eso dejÃ³ de inferir). Si  
Â sigue sin inferir despuÃ©s del fix, hay que investigar si GStreamer estÃ¡ entregando frames correctamente con  
Â rates muy bajos.

---

Â ArreglÃ© el Ãºltimo issue - RTSPStream.Stop() ahora limpia el estado correctamente para permitir reiniciar el  
Â stream.  
  
Â El Problema  
  
Â Cuando setInferenceRate() intentaba reiniciar el stream:  
Â stream.Stop() Â Â // â† cancel != nil despuÃ©s de esto  
Â stream.Start() Â // âœ— Error: "stream already started"  
  
Â El check en Start() fallaba porque cancel seguÃ­a siendo != nil.  
  
Â La SoluciÃ³n  
  
Â AgreguÃ© state reset en Stop() (rtsp.go:467-479):  
  
Â // Reset state to allow restart (critical for hot-reload)  
Â s.cancel = nil  
Â s.ctx = nil  
Â s.pipeline = nil  
Â s.appsink = nil  
Â s.videorate = nil  
Â s.capsfilter = nil  
  
Â // Recreate channels for restart (frames closed by runPipeline defer)  
Â s.frames = make(chan types.Frame, 10)  
Â s.done = make(chan struct{})  
  
Â ---  
Â â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
Â Restartable Components Pattern: Para que un componente sea restartable, Stop() debe:  
Â 1. Cancelar operaciones en curso (context cancel)  
Â 2. Esperar limpieza de recursos (WaitGroup)  
Â 3. Resetear estado a "virgin" state (nil all lifecycle fields)  
Â 4. Recrear ephemeral resources (channels)  
  
Â Este pattern es consistente con el que usamos en PythonPersonDetector - ambos componentes ahora soportan  
Â mÃºltiples ciclos Start/Stop.  
Â â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
  
Â ---  
Â Flujo Completo del FPS Change  
  
Â Ahora el flujo funciona end-to-end:  
  
Â 1. Usuario: make config-rate â†’ 0.5 Hz  
Â 2. MQTT: Command llega a setInferenceRate()  
Â 3. Stream Stop: Pipeline se detiene, estado reset a nil  
Â 4. Config Update: SetTargetFPS(0.5) actualiza targetFPS  
Â 5. Stream Start: Nuevo pipeline con framerate=1/2  
Â 6. Frames Flow: Inferences continÃºan a 0.5 Hz (~2s interrupciÃ³n)  
  
Â El sistema ahora soporta hot-reload de inference rate con reinicio automÃ¡tico del stream! ğŸš€h  
  
Â PodÃ©s probarlo:  
Â make run  
Â make config-rate Â # Cambia a 0.1 Hz o 0.5 Hz  
Â # Observa logs: "stopping stream" â†’ "stream restarted successfully"


â— Â¡Fix Aplicado! âœ“  
  
Â Problema Encontrado: El goroutine consumeFrames morÃ­a cuando el stream se reiniciaba porque leÃ­a de un  
Â channel que se cerrÃ³.  
  
Â Root Cause  
  
Â // consumer.go:28-32  
Â case frame, ok := <-o.stream.Frames():  
Â Â Â Â Â if !ok {  
Â Â Â Â Â Â Â Â Â slog.Info("stream channel closed", "total_frames", frameCount)  
Â Â Â Â Â Â Â Â Â return Â // â† Goroutine muere aquÃ­  
Â Â Â Â Â }  
  
Â Timeline:  
Â 1. stream.Stop() â†’ cierra channel viejo  
Â 2. consumeFrames recibe ok == false â†’ goroutine muere  
Â 3. stream.Start() â†’ crea channel nuevo  
Â 4. âŒ Nadie lee el nuevo channel â†’ frames acumulan pero no se procesan  
  
Â ---  
Â SoluciÃ³n  
  
Â Agregado en commands.go:190-193:  
  
Â // Re-launch consumeFrames goroutine (killed when old stream channel closed)  
Â o.wg.Add(1)  
Â go o.consumeFrames(o.runCtx)  
Â slog.Info("consumeFrames goroutine restarted")  
  
Â Ahora despuÃ©s del stream restart, se relanza el goroutine que consume frames del nuevo channel.  
  
Â ---  
Â â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
Â Goroutine Lifecycle Management: Cuando un component restart cierra channels que goroutines estÃ¡n leyendo,  
Â esos goroutines mueren. Para componentes restartables, necesitÃ¡s:  
  
Â 1. Detectar cuÃ¡ndo goroutines dependientes mueren (channel closed)  
Â 2. Re-lanzar esos goroutines despuÃ©s del restart  
Â 3. Track con WaitGroup para shutdown limpio  
  
Â Este pattern es comÃºn en services que soportan hot-reload: Postgres connection pools, HTTP servers con  
Â graceful restart, etc.  
Â â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
  
Â ---  
Â PodÃ©s Probar Ahora  
  
Â make run  
Â make config-rate Â # Cambia a 0.5 Hz o 0.1 Hz  
  
Â DeberÃ­as ver en logs:  
Â "msg":"stream channel closed" Â Â Â Â Â Â Â Â Â â† Goroutine viejo muere  
Â "msg":"consumeFrames goroutine restarted" Â â† Nuevo goroutine arranca  
Â "msg":"stream restarted successfully"  
  
Â Y las inferences deberÃ­an continuar despuÃ©s del restart! ğŸ¯n